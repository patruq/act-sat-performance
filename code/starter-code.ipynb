{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do States with higher overall participation rates from year over year have better SAT and/or ACT outcomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "sat_2017 = pd.read_csv(\"../data/sat_2017.csv\")\n",
    "act_2017 = pd.read_csv(\"../data/act_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "sat_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>3%</td>\n",
       "      <td>612</td>\n",
       "      <td>603</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>5%</td>\n",
       "      <td>623</td>\n",
       "      <td>604</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Texas</td>\n",
       "      <td>62%</td>\n",
       "      <td>513</td>\n",
       "      <td>507</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Utah</td>\n",
       "      <td>3%</td>\n",
       "      <td>624</td>\n",
       "      <td>614</td>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>60%</td>\n",
       "      <td>562</td>\n",
       "      <td>551</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>65%</td>\n",
       "      <td>561</td>\n",
       "      <td>541</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Washington</td>\n",
       "      <td>64%</td>\n",
       "      <td>541</td>\n",
       "      <td>534</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>14%</td>\n",
       "      <td>558</td>\n",
       "      <td>528</td>\n",
       "      <td>1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3%</td>\n",
       "      <td>642</td>\n",
       "      <td>649</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>3%</td>\n",
       "      <td>626</td>\n",
       "      <td>604</td>\n",
       "      <td>1230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Participation  Evidence-Based Reading and Writing  Math  \\\n",
       "41   South Dakota            3%                                 612   603   \n",
       "42      Tennessee            5%                                 623   604   \n",
       "43          Texas           62%                                 513   507   \n",
       "44           Utah            3%                                 624   614   \n",
       "45        Vermont           60%                                 562   551   \n",
       "46       Virginia           65%                                 561   541   \n",
       "47     Washington           64%                                 541   534   \n",
       "48  West Virginia           14%                                 558   528   \n",
       "49      Wisconsin            3%                                 642   649   \n",
       "50        Wyoming            3%                                 626   604   \n",
       "\n",
       "    Total  \n",
       "41   1216  \n",
       "42   1228  \n",
       "43   1020  \n",
       "44   1238  \n",
       "45   1114  \n",
       "46   1102  \n",
       "47   1075  \n",
       "48   1086  \n",
       "49   1291  \n",
       "50   1230  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   State                               51 non-null     object\n",
      " 1   Participation                       51 non-null     object\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64 \n",
      " 3   Math                                51 non-null     int64 \n",
      " 4   Total                               51 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 7)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>80%</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Texas</td>\n",
       "      <td>45%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Utah</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>29%</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29%</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29%</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69%</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100%</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State Participation  English  Math  Reading  Science Composite\n",
       "42   South Dakota           80%     20.7  21.5     22.3     22.0      21.8\n",
       "43      Tennessee          100%     19.5  19.2     20.1     19.9      19.8\n",
       "44          Texas           45%     19.5  20.7     21.1     20.9      20.7\n",
       "45           Utah          100%     19.5  19.9     20.8     20.6      20.3\n",
       "46        Vermont           29%     23.3  23.1     24.4     23.2      23.6\n",
       "47       Virginia           29%     23.5  23.3     24.6     23.5      23.8\n",
       "48     Washington           29%     20.9  21.9     22.1     22.0      21.9\n",
       "49  West Virginia           69%     20.0  19.4     21.2     20.5      20.4\n",
       "50      Wisconsin          100%     19.7  20.4     20.6     20.9      20.5\n",
       "51        Wyoming          100%     19.4  19.8     20.8     20.6     20.2x"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   English        52 non-null     float64\n",
      " 3   Math           52 non-null     float64\n",
      " 4   Reading        52 non-null     float64\n",
      " 5   Science        52 non-null     float64\n",
      " 6   Composite      52 non-null     object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 3.0+ KB\n"
     ]
    }
   ],
   "source": [
    "act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "In the sat_2017 file, we see that it is detailing the breakdown of participation percentages and the mean of testing scores across 3 different categories, by state. The sat_2017 dataset has 5 columns. The 'State' and 'Participation' columns contain string object values, Patricipation presumably because they were initially entered in with the '%' sign. Every column appears to have 51 rows.\n",
    "\n",
    "In the act_2017 file, we see that it shows the participation percentages and mean testing scores across 5 different testing categories, by both state <b>and</b> at the national level. There are 7 columns (2 more than the sat_2017 dataset). As with the previous dataset, the 'State' column and 'Participation' columns contains string object values, Patricipation presumably because they are displayed with the '%' sign. Every column has 52 rows. We may initially say that one reason for the 1+ column more than the sat_2017 dataset is due to the fact that the act_2017 has <i>national averages</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. Does the data look complete? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State            0\n",
       "Participation    0\n",
       "English          0\n",
       "Math             0\n",
       "Reading          0\n",
       "Science          0\n",
       "Composite        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_2017.isna().sum()\n",
    "act_2017.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Compared with one another, the overall row counts between the two datasets do not match. The ACT dataset has 1 more entry than the SAT. One explanation for this is a row in the ACT dataset specifically for national averages. This would indiate that the <b>SAT dataset may not be complete.</b>\n",
    "\n",
    "Taken only in terms of one dataset in itself, given that each column contains the same number of rows, and no column in either dataset has any NaN / missing values, <b>the data does look to be complete intra-dataset</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "Minimum possible value for each test/subtest, SAT: <b>200 / Subtest</b>\n",
    "\n",
    "Maximum possible value for each test/subtest, SAT: <b>800 / Subtest</b>\n",
    "    \n",
    "Minimum possible value for each test/subtest, ACT: <b>1 / Subtest</b>\n",
    "\n",
    "Maximum possible value for each test/subtest, ACT: <b>36 / Subtest</b>\n",
    "\n",
    "There is also a possible outlier sat_2017 Math column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The min in the sat_2017 column is well below the lowest possible score for the SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     51.000000\n",
      "mean     547.627451\n",
      "std       84.909119\n",
      "min       52.000000\n",
      "25%      522.000000\n",
      "50%      548.000000\n",
      "75%      599.000000\n",
      "max      651.000000\n",
      "Name: Math, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(sat_2017[\"Evidence-Based Reading and Writing\"].describe())\n",
    "print(sat_2017[\"Math\"].describe())\n",
    "\n",
    "# print(act_2017[\"English\"].describe())\n",
    "# print(act_2017[\"Math\"].describe())\n",
    "# print(act_2017[\"Reading\"].describe())\n",
    "# print(act_2017[\"Science\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 Maryland\n",
       "Participation                              69%\n",
       "Evidence-Based Reading and Writing         536\n",
       "Math                                        52\n",
       "Total                                     1060\n",
       "Name: 20, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "sat_2017[\"Math\"].loc[20] # 20 is the cell that is throwing off the col\n",
    "sat_2017.loc[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "sat_2017.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation     object\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "The 'Participation' columns in both the sat_2017 and act_2017 datasets should not be a string type, we want to perform any calculations on it.\n",
    "These should most likely be cast into floats.\n",
    "\n",
    "The 'Composite' column in the act_2017 column is also a Series-Object / string. The values in this column are numeric, and should also most likely be cast into floats or integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "def format_participation(participation):\n",
    "    try:\n",
    "        return float(participation)\n",
    "    except ValueError:\n",
    "        participation = participation[:-1]\n",
    "        return float(participation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_2017[\"Participation\"] = sat_2017[\"Participation\"].apply(format_participation)\n",
    "act_2017[\"Participation\"] = act_2017[\"Participation\"].apply(format_participation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some values in actact_2017[\"Composite\"] have alphabet characters in them.\n",
    "# act_2017.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.3     3\n",
       "19.8     3\n",
       "21.4     3\n",
       "23.6     2\n",
       "19.4     2\n",
       "21.8     2\n",
       "24.2     2\n",
       "24.1     2\n",
       "21.9     2\n",
       "20.4     2\n",
       "19.7     2\n",
       "25.2     1\n",
       "22.6     1\n",
       "20.8     1\n",
       "23.9     1\n",
       "19.0     1\n",
       "23.8     1\n",
       "24.3     1\n",
       "20.5     1\n",
       "20.2x    1\n",
       "25.5     1\n",
       "18.6     1\n",
       "24.0     1\n",
       "21.0     1\n",
       "20.7     1\n",
       "18.7     1\n",
       "19.5     1\n",
       "17.8     1\n",
       "25.4     1\n",
       "19.2     1\n",
       "22.8     1\n",
       "22.0     1\n",
       "21.5     1\n",
       "23.7     1\n",
       "19.1     1\n",
       "21.7     1\n",
       "22.3     1\n",
       "20.0     1\n",
       "Name: Composite, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which values in Composite contain a non-numeric character:\n",
    "act_2017[\"Composite\"].value_counts() # Output = last cell in this col has the non-numeric character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "def format_composite(composite):\n",
    "    try:\n",
    "        return float(composite)\n",
    "    except ValueError:\n",
    "        composite = composite[:-1]\n",
    "        return float(composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2017[\"Composite\"] = act_2017[\"Composite\"].apply(format_composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check \n",
    "# act_2017.dtypes\n",
    "# act_2017.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Washington</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State  Participation  English  Math  Reading  Science  Composite\n",
       "47       Virginia           29.0     23.5  23.3     24.6     23.5       23.8\n",
       "48     Washington           29.0     20.9  21.9     22.1     22.0       21.9\n",
       "49  West Virginia           69.0     20.0  19.4     21.2     20.5       20.4\n",
       "50      Wisconsin          100.0     19.7  20.4     20.6     20.9       20.5\n",
       "51        Wyoming          100.0     19.4  19.8     20.8     20.6       20.2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "sat_2017.head()\n",
    "act_2017.head()\n",
    "sat_2017.tail()\n",
    "act_2017.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State             object\n",
       "Participation    float64\n",
       "English          float64\n",
       "Math             float64\n",
       "Reading          float64\n",
       "Science          float64\n",
       "Composite        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "sat_2017.dtypes\n",
    "act_2017.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "sat_2017_mapping = {\"State\": \"state\", \n",
    "               \"Participation\": \"sat_2017_participation\", \n",
    "               \"Evidence-Based Reading and Writing\": \"sat_2017_reading_writing\", \n",
    "               \"Math\": \"sat_2017_math\",\n",
    "               \"Total\": \"sat_2017_total\"}\n",
    "\n",
    "act_2017_mapping = {\"State\": \"state\", \n",
    "               \"Participation\": \"act_2017_participation\", \n",
    "               \"English\": \"act_2017_english\", \n",
    "               \"Math\": \"act_2017_math\", \n",
    "               \"Reading\": \"act_2017_reading\",\n",
    "               \"Science\": \"act_2017_science\",\n",
    "               \"Composite\": \"act_2017_composite\"}\n",
    "\n",
    "sat_2017.rename(columns=sat_2017_mapping, inplace=True)\n",
    "act_2017.rename(columns=act_2017_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|SAT|The state in which the test has been taken|\n",
    "|participation|float|SAT|The percentage of students haven taken the SAT (Ex: 60.0 = 60%)|\n",
    "|reading_writing|int|SAT|The average score earned in evident-based reading & writing by state|\n",
    "|math|int|SAT|The average score earned by students in math by state|\n",
    "|total|int|SAT|Total earned score acros both reading_writing and math by state|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|ACT|The state in which the test has been taken|\n",
    "|participation|float|ACT|The percentage of students haven taken the ACT (Ex 75.0 = 75%)|\n",
    "|english|float|ACT|Average score earned in English subtest by state|\n",
    "|math|float|ACT|Average score earned in Math subtest by state|\n",
    "|reading|float|ACT|Average score earned in Reading subtest by state|\n",
    "|science|float|ACT|Average score earned in Science subtest by state\n",
    "|composite|float|ACT|Average score across English, Math, Reading, and Science by state|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sat_2017\n",
    "# sat_2017[\"state\"].duplicated()  # No duplicates in SAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act_2017  # Has 1 extra row than sat_2017\n",
    "# act_2017[\"state\"].duplicated()  # No duplicates in ACT\n",
    "# Extra row in row 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_2017_participation</th>\n",
       "      <th>act_2017_english</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_reading</th>\n",
       "      <th>act_2017_science</th>\n",
       "      <th>act_2017_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  act_2017_participation  act_2017_english  act_2017_math  \\\n",
       "0  National                    60.0              20.3           20.7   \n",
       "1   Alabama                   100.0              18.9           18.4   \n",
       "\n",
       "   act_2017_reading  act_2017_science  act_2017_composite  \n",
       "0              21.4              21.0                21.0  \n",
       "1              19.7              19.4                19.2  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_2017.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>act_2017_participation</th>\n",
       "      <th>act_2017_english</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_reading</th>\n",
       "      <th>act_2017_science</th>\n",
       "      <th>act_2017_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  act_2017_participation  act_2017_english  act_2017_math  \\\n",
       "1  Alabama                   100.0              18.9           18.4   \n",
       "2   Alaska                    65.0              18.7           19.8   \n",
       "\n",
       "   act_2017_reading  act_2017_science  act_2017_composite  \n",
       "1              19.7              19.4                19.2  \n",
       "2              20.4              19.9                19.8  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code\n",
    "act_2017.drop(0, inplace=True)\n",
    "act_2017.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2017.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_2017_participation</th>\n",
       "      <th>sat_2017_reading_writing</th>\n",
       "      <th>sat_2017_math</th>\n",
       "      <th>sat_2017_total</th>\n",
       "      <th>act_2017_participation</th>\n",
       "      <th>act_2017_english</th>\n",
       "      <th>act_2017_math</th>\n",
       "      <th>act_2017_reading</th>\n",
       "      <th>act_2017_science</th>\n",
       "      <th>act_2017_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5.0</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  sat_2017_participation  sat_2017_reading_writing  sat_2017_math  \\\n",
       "0  Alabama                     5.0                       593            572   \n",
       "\n",
       "   sat_2017_total  act_2017_participation  act_2017_english  act_2017_math  \\\n",
       "0            1165                   100.0              18.9           18.4   \n",
       "\n",
       "   act_2017_reading  act_2017_science  act_2017_composite  \n",
       "0              19.7              19.4                19.2  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code:\n",
    "combined_2017_df = sat_2017.merge(act_2017, \n",
    "                                  how=\"outer\", \n",
    "                                  on=\"state\")\n",
    "\n",
    "combined_2017_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "combined_2017_df.to_csv(\"../data/combined_2017.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the `sat_2018.csv` and `act_2018.csv` files and assign them to appropriately named pandas dataframes. For the **2018 ACT Data**, only the `Composite` scores are available. Repeat the same processes to clean the 2018 data here as you were instructed in the previous sections above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "sat_2018 = pd.read_csv(\"../data/sat_2018.csv\")\n",
    "act_2018 = pd.read_csv(\"../data/act_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column                              Non-Null Count  Dtype \n",
      "---  ------                              --------------  ----- \n",
      " 0   State                               51 non-null     object\n",
      " 1   Participation                       51 non-null     object\n",
      " 2   Evidence-Based Reading and Writing  51 non-null     int64 \n",
      " 3   Math                                51 non-null     int64 \n",
      " 4   Total                               51 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Display Data\n",
    "# sat_2018\n",
    "# sat_2018.head(10)\n",
    "# sat_2018.tail(10)\n",
    "sat_2018.info()\n",
    "# sat_2018.describe()\n",
    "# sat_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   State          52 non-null     object \n",
      " 1   Participation  52 non-null     object \n",
      " 2   Composite      52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# act_2018\n",
    "# act_2018.head(10)\n",
    "# act_2018.tail(10)\n",
    "act_2018.info()\n",
    "# act_2018.describe()\n",
    "# act_2018.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbally Describe Data\n",
    "SAT 2018: \n",
    "The sat_2018 dataset contains a string column of state names, a string column of 'percentages' of participation by state, and 3 integer columns: 1 Evidence-Based Reading and Writing, 1 Math, and column of the totals of the previous two integer columns. None of the min or max values in any integer column seems like outside the boundaries of possible scores. Each Column has 51 non-null values.\n",
    "\n",
    "ACT 2018:\n",
    "The act_2018 dataset contains a string column of state names, a string column of 'percentages' of participation by state, and 1 integer column: the Composite score, which as average of a student's score across the 4 subtest types. None of the min or max values seems outside of the limits for scores. This dataset has 52 rows, 1 more than the sat_2018 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A- Does the data look complete?\n",
    "Neither the sat_2018 or act_2018 dataset has any NaN/missing values. This indicates that the data is complete.\n",
    "\n",
    "The act_2018 DF does have one additional column that the sat_2018 DF does not have. The act_2018 DF is also missing columns that the act_2017 DF contained, indicating that, year over year, we are missing data. The act_2018 DF only contains the Participation and Composite columns for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sat_2018.isna().sum()\n",
    "# act_2018.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B- Are there any obvious issues with the data?\n",
    "The Participation columns of both dataframes will need to be converted to an appropriate datatype (type float). The column names in both DF's will also need to be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Maine</td>\n",
       "      <td>7%</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    State Participation  Composite\n",
       "20  Maine            7%       24.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C- Fix errors\n",
    "# Find the reason why act_2018 has more rows:\n",
    "act_2018[act_2018.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2018.drop(20, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2018.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                                 object\n",
       "Participation                         object\n",
       "Evidence-Based Reading and Writing     int64\n",
       "Math                                   int64\n",
       "Total                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the dtypes?\n",
    "sat_2018.dtypes\n",
    "# act_2018.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the wrong dtypes\n",
    "sat_2018[\"Participation\"] = sat_2018[\"Participation\"].apply(format_participation)\n",
    "act_2018[\"Participation\"] = act_2018[\"Participation\"].apply(format_participation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cols\n",
    "sat_2018.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"sat_2018_participation\",\n",
    "                         \"Evidence-Based Reading and Writing\": \"sat_2018_reading_writing\",\n",
    "                         \"Math\": \"sat_2018_math\",\n",
    "                         \"Total\": \"sat_2018_total\"}, \n",
    "                         inplace=True)\n",
    "act_2018.rename(columns={\"State\": \"state\",\n",
    "                         \"Participation\": \"act_2018_participation\",\n",
    "                         \"Composite\": \"act_2018_composite\"},\n",
    "                         inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionaries for SAT & ACT 2018\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|SAT|The state in which the test has been taken|\n",
    "|participation|float|SAT|The percentage of students haven taken the SAT (Ex: 60.0 = 60%)|\n",
    "|reading_writing|int|SAT|The average score earned in evident-based reading & writing by state|\n",
    "|math|int|SAT|The average score earned by students in math by state|\n",
    "|total|int|SAT|Total earned score acros both reading_writing and math by state|\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|state|object|ACT|The state in which the test has been taken|\n",
    "|participation|float|ACT|The percentage of students haven taken the ACT (Ex 75.0 = 75%)|\n",
    "|composite|float|ACT|Average score across English, Math, Reading, and Science by state|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>sat_2018_participation</th>\n",
       "      <th>sat_2018_reading_writing</th>\n",
       "      <th>sat_2018_math</th>\n",
       "      <th>sat_2018_total</th>\n",
       "      <th>act_2018_participation</th>\n",
       "      <th>act_2018_composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>6.0</td>\n",
       "      <td>595</td>\n",
       "      <td>571</td>\n",
       "      <td>1166</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  sat_2018_participation  sat_2018_reading_writing  sat_2018_math  \\\n",
       "0  Alabama                     6.0                       595            571   \n",
       "\n",
       "   sat_2018_total  act_2018_participation  act_2018_composite  \n",
       "0            1166                   100.0                19.1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge DFs\n",
    "combined_2018_df = sat_2018.merge(act_2018, on=\"state\")\n",
    "combined_2018_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merge DF\n",
    "combined_2018_df.to_csv(\"../data/combined_2018.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-348b1a08c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/final.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "final.to_csv(\"../data/final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = combined_2017_df.merge(combined_2018_df, on=\"state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "final.describe()\n",
    "# final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "# std = sqrt of sum(xi - mean)^2 / n\n",
    "\n",
    "def calculate_std(df, col):\n",
    "    squared_diffs = 0\n",
    "    for i in df[col]:\n",
    "        squared_diffs += ((i - df[col].mean()) ** 2)  \n",
    "    return (squared_diffs / (df[col].count()-1)) ** 0.5\n",
    "        \n",
    "\n",
    "calculate_std(final, \"sat_2017_reading_writing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "sd = {col: calculate_std(final, col) for col in final.iloc[:, 1:]}\n",
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(final[\"sat_2017_math\"], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "Initally, my manually calculated standard deviation did not match up with the output from pandas `describe`. When I accounted for bias (`n-1`), my manual standard deviation function matches the output \n",
    "\n",
    "Without using the `ddof=1`, numpy's `std` method, the output of the `std` method returned the same output as my own `calculate_std` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below uses a variety of approaches to filter and sort data to return the relevant info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The States with highest participation rates:***\n",
    "\n",
    "- 2017 SAT: Connecticut (100%), Delaware (100%), Michigan (100%)\n",
    "- 2018 SAT: Conneticut (100%), Colorado (100%), Delaware (100%), Idaho (100%), Michigan (100%)\n",
    "- 2017 ACT: Alabama (100%), Montana (100%), Wisconsion (100%), Utah (100%), Tennessee (100%)\n",
    "- 2018 ACT: Alabama (100%), Arkansas (100%), Wisconsin (100%), Utah (100%), Tennessee (100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest Participation by State:\n",
    "\n",
    "high_sat_17_participation = final[\"sat_2017_participation\"] > 75.\n",
    "high_sat_18_participation = final[\"sat_2018_participation\"] > 75.\n",
    "high_act_17_participation = final[\"act_2017_participation\"] > 75.\n",
    "high_act_18_participation = final[\"act_2018_participation\"] > 75.\n",
    "final[high_sat_18_participation].sort_values(\"sat_2018_participation\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The States with lowest participation rates:***\n",
    "\n",
    "- 2017 SAT: Mississippi (2%), North Dakota (2%), Iowa (2%)\n",
    "- 2018 SAT: North Dakota (2%)\n",
    "- 2017 ACT: Maine (8%)\n",
    "- 2018 ACT: Maine (7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lowest Participation by State:\n",
    "\n",
    "final[(final[\"sat_2017_participation\"] < 10)].sort_values(\"sat_2017_participation\", ascending=True).head()\n",
    "final[(final[\"sat_2018_participation\"] < 10)].sort_values(\"sat_2018_participation\", ascending=True).head()\n",
    "final[(final[\"act_2017_participation\"] < 30)].sort_values(\"act_2017_participation\", ascending=True).head()\n",
    "final[(final[\"act_2017_participation\"] < 30)].sort_values(\"act_2017_participation\", ascending=True).head()\n",
    "\n",
    "final[\"sat_2017_total\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Highest Total (SAT) and Composite (ACT) Score by State:***\n",
    "\n",
    "- 2017 SAT: Minnesota (1298)\n",
    "- 2018 SAT: Minnesota (1295)\n",
    "- 2017 ACT: New Hampshire (25.5)\n",
    "- 2018 ACT: Conneticut (25.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest Mean Total/Composite Scores by State:\n",
    "\n",
    "high_2017_total = (final[\"sat_2017_total\"] == final[\"sat_2017_total\"].max())\n",
    "high_2018_total = (final[\"sat_2018_total\"] == final[\"sat_2018_total\"].max())\n",
    "high_2017_compo = (final[\"act_2017_composite\"] == final[\"act_2017_composite\"].max())\n",
    "high_2018_compo = (final[\"act_2018_composite\"] == final[\"act_2018_composite\"].max())\n",
    "final[high_2018_compo].filter([\"state\", \"sat_2017_total\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Lowest Total (SAT) and Composite (ACT) by State:***\n",
    "\n",
    "- 2017 SAT: Delaware (996)\n",
    "- 2018 SAT: Delaware (998)\n",
    "- 2017 ACT: Nevada (17.8)\n",
    "- 2018 ACT: Nevada (17.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lowest Mean Total/Composite Scores by State:\n",
    "\n",
    "# Credit to Alex Golden for showing me the df.filter() method to return only columns I want to observe while filtering/sorting.\n",
    "final[(final[\"sat_2017_total\"] == final[\"sat_2017_total\"].min())].filter([\"state\", \"sat_2017_total\"])\n",
    "final[(final[\"sat_2018_total\"] == final[\"sat_2018_total\"].min())].filter([\"state\", \"sat_2018_total\"])\n",
    "\n",
    "final[(final[\"act_2017_composite\"] == final[\"act_2017_composite\"].min())].filter([\"state\", \"act_2017_composite\"])\n",
    "final[(final[\"act_2018_composite\"] == final[\"act_2018_composite\"].min())].filter([\"state\", \"act_2018_composite\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change in participation, change in score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***States with 100% participation on a given test have a rate change year-to-year?***\n",
    "\n",
    "- Conneticut, Delware, and Michigan all had 100% participation in 2017, and had 100% participation in 2018. There was no change in the participation rate.\n",
    "\n",
    "- 17 states had 100% participation ACT in 2017, and the ACT test in 2018 had 17 states with 100% participation as well.\n",
    "    - Colorado and Minnesota had 100% participation in 2017, but did not in 2018.\n",
    "    - Nebraska and Ohio did not have 100% participation in 2017, but did move up to 100% participation in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_2017_full_particip = (final[final[\"sat_2017_participation\"] == 100]).filter((\"state\", \"sat_2017_participation\"))\n",
    "# print(sat_2017_full_particip)\n",
    "sat_2018_full_particip = (final[final[\"sat_2018_participation\"] == 100]).filter((\"state\", \"sat_2017_participation\"))\n",
    "# print(sat_2018_full_particip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_2017_full_particip = (final[final[\"act_2017_participation\"] == 100]).filter((\"state\", \"act_2017_participation\"))\n",
    "# print(act_2017_full_particip)\n",
    "act_2018_full_particip = (final[final[\"act_2018_participation\"] == 100]).filter((\"state\", \"act_2018_participation\"))\n",
    "# print(\"\\n\", act_2018_full_particip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Do any states show have >50% participation on both tests either year?***\n",
    "\n",
    "- 21 states had > 50% participation on the 2017 SAT.\n",
    "- 25 states had > 50% participation on the 2018 SAT.\n",
    "- Colorado, Illinois, North Caroline, and South Carolina all pushed above 50% participation in 2018 over 2017.\n",
    "\n",
    "- 31 states had > 50% participation on the 2017 ACT.\n",
    "- 28 states had > 50% participation on the 2018 ACT.\n",
    "- Alaska, Colorado, Illinois all did not pass > 50% participation on the 2018 ACT, after reaching > 50% participation on the 2017 ACT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greater_sat_17_part = (final[final[\"sat_2017_participation\"] > 50]).filter((\"state\", \n",
    "                                                                            \"sat_2017_participation\"))\n",
    "print(greater_sat_17_part.count())\n",
    "greater_sat_18_part = (final[final[\"sat_2018_participation\"] > 50]).filter((\"state\", \n",
    "                                                                            \"sat_2018_participation\"))\n",
    "print(greater_sat_18_part.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.loc[final[\"sat_2017_participation\"] > 50][\"state\"]\n",
    "final.loc[final[\"sat_2018_participation\"] > 50][\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(final[final[\"act_2017_participation\"] > 50]).filter((\"state\", \n",
    "                                                      \" act_2017_participation\")).count()\n",
    "(final[final[\"act_2018_participation\"] > 50]).filter((\"state\", \n",
    "                                                      \"act_2018_participation\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((final[final[\"act_2017_participation\"] > 50])[\"state\"])\n",
    "print((final[final[\"act_2018_participation\"] > 50])[\"state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish size of figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(final.corr(),\n",
    "            cmap=\"YlGnBu\",\n",
    "            annot=True)\n",
    "plt.title(\"General Relation of Data Across All Categories\", fontsize=20, pad=20.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(final.iloc[:, :5].corr(),\n",
    "            cmap=\"YlGnBu\",\n",
    "            annot=True)\n",
    "plt.title(\"National Correlation 2017\", fontsize=20, pad=20.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(final.iloc[:, 10:14].corr(),\n",
    "            cmap=\"coolwarm\",\n",
    "            annot=True)\n",
    "plt.title(\"National Correlation 2018\", fontsize=20, pad=20.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Inside of each test year, and according the relevant test, the correlation tends to be quite strong between participation and subtest scores - although the SAT 2017, ACT 2017, SAT 2018, and ACT 2018 participation has a negative correlation to respective testing scores.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot\n",
    "        plt[i].title(dataframe[column])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "subplot_histograms(combined_2017_df, [\"sat_2017_participation\", \"act_2017_participation\"], \n",
    "                          [\"SAT Participation\", \"ACT Participation\"],\n",
    "                           \"X-label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Distributions of participation for SAT/ACT over both 2017 and 2018:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot(2, 1, 1)\n",
    "ax1.set_title(\"SAT 2017 Participation\")\n",
    "ax1.hist(final[\"sat_2017_participation\"])\n",
    "ax1.vlines(x=np.mean(final[\"sat_2017_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2, sharex=ax1)\n",
    "ax2.set_title(\"SAT 2018 Participation\")\n",
    "ax2.hist(final[\"sat_2018_participation\"])\n",
    "ax2.vlines(x=np.mean(final[\"sat_2018_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "ax1 = plt.subplot(4, 1, 1)\n",
    "ax1.set_title(\"ACT 2017 Participation\")\n",
    "ax1.hist(final[\"act_2017_participation\"])\n",
    "ax1.vlines(x=np.mean(final[\"act_2017_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "ax2 = plt.subplot(4, 1, 2, sharex=ax1)  # sharex, as the values have the same possible ranges \n",
    "ax2.set_title(\"ACT 2018 Participation\")\n",
    "ax2.hist(final[\"act_2018_participation\"])\n",
    "ax2.vlines(x=np.mean(final[\"act_2018_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "ax3 = plt.subplot(4, 1, 3, sharex=ax1)\n",
    "ax3.set_title(\"SAT 2017 Participation\")\n",
    "ax3.hist(final[\"sat_2017_participation\"])\n",
    "ax3.vlines(x=np.mean(final[\"sat_2017_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "ax4 = plt.subplot(4, 1, 4, sharex=ax1)\n",
    "ax4.set_title(\"SAT 2018 Participation\")\n",
    "ax4.hist(final[\"sat_2018_participation\"])\n",
    "ax4.vlines(x=np.mean(final[\"sat_2018_participation\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Distributions of math scores for SAT/ACT available years:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax1 = plt.subplot(3, 1, 1)\n",
    "ax1.set_title(\"ACT 2017 Math Scores\")\n",
    "ax1.hist(final[\"act_2017_math\"])\n",
    "ax1.vlines(x=np.mean(final[\"act_2017_math\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 15,\n",
    "          color = \"red\");\n",
    "\n",
    "ax2 = plt.subplot(3, 1, 2)  # If sharex == True, The scale of x axis is too small for the SAT score setup\n",
    "ax2.set_title(\"All SAT 2017 Math Scores\")\n",
    "ax2.hist(final[\"sat_2017_math\"])\n",
    "ax2.vlines(x=np.mean(final[\"sat_2017_math\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 20,\n",
    "          color = \"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Distributions of reading/verbal scores for SAT/ACT available years:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax1= plt.subplot(2, 1, 1)\n",
    "ax1.set_title(\"ACT 2017 Reading/Verbal Scores\")\n",
    "ax1.hist(final[\"act_2017_reading\"])\n",
    "ax1.vlines(x=np.mean(final[\"act_2017_reading\"]),\n",
    "          ymin = 0,\n",
    "          ymax = 12,\n",
    "          color = \"red\");\n",
    "\n",
    "ax2 = plt.subplot(2, 1, 2)\n",
    "ax2.set_title(\"SAT 2017 Reading/Verbal Scores\")\n",
    "ax2.hist(final[\"sat_2017_reading_writing\"])\n",
    "ax2.vlines(x=np.mean(final[\"sat_2017_reading_writing\"]),\n",
    "          ymin = 0,\n",
    "          ymax= 10,\n",
    "          color = \"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Histograms\n",
    "\n",
    "- It is difficult is some cases to compare the scores between the SAT and ACT: because of the different grading system, there isn't easy to find good jumping off points for measuring the differences between the two.\n",
    "- That being said, the distribution (dist) for the ACT 2017 Math scores are fairly spread out. The SAT 2017 Math scores may be less spread, however, there is a likely outlier data point throwing off the dist visuals.\n",
    "\n",
    "- The ACT 2017 Reading/Verbal scores are fairly spread out. The SAT 2017 Reading/Verbal scores have two 'peaks', indicating it could be bimonal dist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT v ACT Math Scores for 2017:\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(final[\"sat_2017_math\"],\n",
    "            final[\"act_2017_math\"],\n",
    "            color=\"orange\");\n",
    "plt.title(\"Math Scores 2017: SAT v. ACT\")\n",
    "plt.ylabel(\"ACT Math Scores\", fontsize=15)\n",
    "plt.xlabel(\"SAT Math Scores\", fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT v ACT verbal scores for 2017:\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(final[\"sat_2017_reading_writing\"],\n",
    "            final[\"act_2017_reading\"],\n",
    "            c=\"blue\");\n",
    "plt.title(\"Verbal/Reading Scores 2017: SAT v. ACT\")\n",
    "plt.ylabel(\"ACT Reading Scores\", fontsize=15)\n",
    "plt.xlabel(\"SAT Reading/Verbal Scores\", fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAT v. AV total/composite scores for 2017\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(final[\"sat_2017_total\"],\n",
    "            final[\"act_2017_composite\"],\n",
    "            c=\"red\")\n",
    "plt.title(\"SAT Total v. ACT Composite 2017\")\n",
    "plt.ylabel(\"ACT Composite Scores\", fontsize=15)\n",
    "plt.xlabel(\"SAT Total Scores\", fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total scores for SAT 2017 vs 2018\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(final[\"sat_2017_total\"],\n",
    "            final[\"sat_2018_total\"],\n",
    "            c=\"brown\")\n",
    "plt.title(\"SAT Total Score 2017 v. 2018\")\n",
    "plt.ylabel(\"SAT Total Score 2018\", fontsize=15)\n",
    "plt.xlabel(\"SAT Total Score 2017\", fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite scores for ACT 2017 vs. 2018\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(final[\"act_2017_composite\"],\n",
    "            final[\"act_2018_composite\"],\n",
    "            c=\"orange\")\n",
    "plt.title(\"ACT Composite Scores: 2017 v. 2018\")\n",
    "plt.ylabel(\"ACT 2018 Composite Scores\", fontsize=15)\n",
    "plt.xlabel(\"ACT 2017 Composite Scores\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.describe()  # Find appropriate ranges to be compared in a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-3984813b86a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Did some research via stackoverflow to find something to make this work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# source URL: https://stackoverflow.com/questions/51777217/how-to-plot-a-boxplot-for-each-column-in-a-dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "# All box plots of numeric values in the final DF:\n",
    "\n",
    "# Did some research via stackoverflow to find something to make this work\n",
    "# source URL: https://stackoverflow.com/questions/51777217/how-to-plot-a-boxplot-for-each-column-in-a-dataframe\n",
    "for col in final.iloc[:, 1:]:\n",
    "    plt.figure()  \n",
    "    final.boxplot([col], color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "sns.boxplot(final[\"sat_2017_participation\"], color=\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "sns.boxplot(final[\"sat_2018_participation\"], color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot Interpretations and Observations:\n",
    "\n",
    "- The SAT 2017 participation (partic) has quartiles on the lower end of the overall spread. The ACT 2017 partic is the inverse of that.\n",
    "\n",
    "- Very little amount of spread indicated in the SAT 2017 Math box plot. THe same for ACT 2017 Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***3 States to research:***\n",
    "\n",
    "- Connecticut (high participation, high totals/composites)\n",
    "    - https://portal.ct.gov/-/media/SDE/Student-Assessment/SAT/sat_faqs_superintendents.pdf\n",
    "    - Gov Malloy sought and won approval for a waiver from US Dept of Ed to use SATs as the high school accountability measure\n",
    "    - Starting late-2015, both in-person and technology based prof dev for teachers, students, parents, and others\n",
    "    - accommodations for students with disabilities\n",
    "    - Conn requires all 11th graders to take the SATs\n",
    "- Minnesota (drop in participation %)\n",
    "    - Very little info, appears to not have any if at all official policies regarding the taking of either SAT or ACT\n",
    "- Delaware (High 2017 participation, low score total 2017)\n",
    "    - https://www.udel.edu/apply/undergraduate-admissions/requirements/\n",
    "    - For incoming state uni students, SAT is optional in admission decision\n",
    "    - Seems primarily uni focused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conclusions***\n",
    "\n",
    "- One of the best examples of the relationship between participation and performance is Connecticut. With 100% participation year over year 2017-2018, this state has the highest composite score for 2018 (it should be noted that Connecticut scores were highest in ACT.\n",
    "\n",
    "***Suggestions***\n",
    "\n",
    "- Connecticut, a state with 100% year over year participation and high performance metrics, has moved forward with policies replacing state-issued standardized tests for the SAT. More policies like these will lead to better performance for incoming students.\n",
    "\n",
    "\n",
    "***Additional Info Desired***\n",
    "\n",
    "- In under standing the impact of state-wide participation on test outcomes, it would be useful to see participation data for the PSAT (or PreACT for ACT). Looking at participation in test-prep could shed more light on the effects of participation to score outcomes.\n",
    "\n",
    "- What %'s of graduating high-school students that have taken the SAT or ACT have been accepted into 4 year universities? What about ones that have not? Data on whether students are in a position where the SAT or ACT is necesary for admissions could effect overall participation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores? \n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
